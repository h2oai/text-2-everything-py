# Simple H2O Drive Upload Script

This Python script is a standalone version of the `Simple_Drive_Upload.ipynb` Jupyter notebook, converted for command-line usage and automation.

## Overview

The script demonstrates how to upload local data files to H2O Drive using a simple, direct approach. It provides:

- Direct connection to H2O Drive
- Loading of local project data from filesystem
- Upload of files to Drive with organized structure
- Verification of uploads and listing of Drive contents
- Progress tracking and detailed reporting

## Features

- **Command-line interface** - Easy to use from terminal or scripts
- **Environment configuration** - Supports `.env` files for secure credential management
- **Comprehensive error handling** - Detailed error messages and validation
- **Progress tracking** - Real-time upload progress and results
- **Verification** - Automatic verification of uploaded files
- **Organized structure** - Maintains proper folder structure in Drive

## Installation

1. Install required dependencies:
```bash
pip install h2o-cloud-discovery
pip install 'h2o-drive>=4'
pip install python-dotenv
```

Or use the requirements file:
```bash
pip install -r requirements_drive_integration.txt
```

## Configuration

### Environment Variables

Set the following environment variables:

```bash
export H2O_CLOUD_ENVIRONMENT="https://your-environment.h2o.ai/"
export H2O_CLOUD_CLIENT_PLATFORM_TOKEN="your-token-here"
```

### Environment File (Recommended)

Create a `.env.upload` file in the project directory:

```
H2O_CLOUD_ENVIRONMENT=https://your-environment.h2o.ai/
H2O_CLOUD_CLIENT_PLATFORM_TOKEN=your-token-here
```

## Usage

### Basic Usage

```bash
python simple_drive_upload.py --project-path "JSON - tests" --project-name "my_uploaded_project"
```

### With Custom Environment File

```bash
python simple_drive_upload.py --project-path "data" --project-name "my_project" --env-file ".env.upload"
```

### Command-line Options

- `--project-path` (required): Path to the local project directory containing data to upload
- `--project-name` (required): Name of the project in H2O Drive (will be prefixed with 'home/' if not already)
- `--env-file` (optional): Path to environment file (default: .env.upload)

## Expected Directory Structure

The script expects your local project data to be organized as follows:

```
project_path/
â”œâ”€â”€ schema_metadata/     # JSON files containing schema metadata
â”œâ”€â”€ contexts/           # JSON and TXT files containing context data
â””â”€â”€ golden_examples/    # JSON files containing golden examples
```

## Output Structure in H2O Drive

Files will be uploaded to H2O Drive with the following structure:

```
home/your_project_name/
â”œâ”€â”€ schema_metadata/
â”‚   â”œâ”€â”€ file1.json
â”‚   â””â”€â”€ file2.json
â”œâ”€â”€ contexts/
â”‚   â”œâ”€â”€ context1.json
â”‚   â”œâ”€â”€ context2.txt
â”‚   â””â”€â”€ context3.json
â””â”€â”€ golden_examples/
    â”œâ”€â”€ example1.json
    â””â”€â”€ example2.json
```

## Example Output

```
ğŸš€ Simple H2O Drive Upload
==================================================
ğŸ”§ Setting up environment...
âœ… Loaded environment from .env.upload
âœ… Environment: https://your-environment.h2o.ai/
âœ… Token: ****abcd
ğŸ”Œ Connecting to H2O Drive...
âœ… Connected to H2O Drive successfully!
ğŸ“ Found 15 objects in your Drive
ğŸ“¥ Loading project data from: JSON - tests
ğŸ“„ Found 3 schema metadata files
ğŸ“„ Found 5 context files (3 JSON, 2 TXT)
ğŸ“„ Found 2 golden example files

ğŸ“Š Loaded Project Data Summary:
  - schema_metadata: 3 files
    â€¢ schema1.json
    â€¢ schema2.json
    â€¢ schema3.json
  - contexts: 5 files
    â€¢ context1.json
    â€¢ context2.txt
    â€¢ context3.json
  - golden_examples: 2 files
    â€¢ example1.json
    â€¢ example2.json

âœ… Total files loaded: 10
ğŸš€ Starting upload to H2O Drive...
ğŸ“ Project name: home/my_uploaded_project

ğŸ“¤ Uploading 3 schema_metadata files...
  âœ… Uploaded schema1.json
  âœ… Uploaded schema2.json
  âœ… Uploaded schema3.json

ğŸ“¤ Uploading 5 contexts files...
  âœ… Uploaded context1.json
  âœ… Uploaded context2.txt
  âœ… Uploaded context3.json

ğŸ“¤ Uploading 2 golden_examples files...
  âœ… Uploaded example1.json
  âœ… Uploaded example2.json

ğŸ” Verifying uploads in H2O Drive...

ğŸ“ Found 10 files for project 'home/my_uploaded_project':

  ğŸ“‚ schema_metadata: 3 files
    â€¢ schema1.json
    â€¢ schema2.json
    â€¢ schema3.json

  ğŸ“‚ contexts: 5 files
    â€¢ context1.json
    â€¢ context2.txt
    â€¢ context3.json

  ğŸ“‚ golden_examples: 2 files
    â€¢ example1.json
    â€¢ example2.json

ğŸ“‹ Upload Session Summary:
========================================
ğŸ“Š Files processed: 10
âœ… Successfully uploaded: 10
âŒ Failed uploads: 0
ğŸ“ˆ Success rate: 100.0%
ğŸ“ Project name in Drive: home/my_uploaded_project

ğŸ“Š Upload Results by Type:
------------------------------
âœ… schema_metadata: 3 successful, 0 failed
âœ… contexts: 5 successful, 0 failed
âœ… golden_examples: 2 successful, 0 failed

ğŸ‰ Simple Drive Upload Complete!

ğŸ“š What was accomplished:
   â€¢ Connected directly to H2O Drive
   â€¢ Loaded local project data
   â€¢ Uploaded files with organized structure
   â€¢ Verified uploads in Drive
   â€¢ Provided progress tracking

ğŸ‰ All operations completed successfully!
```

## Error Handling

The script provides comprehensive error handling for common issues:

- **Missing environment variables**: Clear instructions on how to set them
- **Connection failures**: Detailed error messages for H2O Drive connection issues
- **File not found**: Validation of project path and file existence
- **Upload failures**: Individual file upload error tracking
- **Verification issues**: Checks to ensure files were uploaded correctly

## Exit Codes

- `0`: All operations completed successfully
- `1`: Upload completed with some issues or verification failed
- `1`: Upload failed completely or configuration error

## Differences from Jupyter Notebook

This script provides several improvements over the original notebook:

1. **Command-line interface** - No need for Jupyter environment
2. **Better error handling** - Comprehensive exception handling and validation
3. **Argument parsing** - Flexible command-line arguments
4. **Environment management** - Secure credential handling with .env files
5. **Exit codes** - Proper exit codes for automation and scripting
6. **Logging** - Structured output with progress indicators
7. **Validation** - Input validation and file existence checks
8. **Cleanup** - Proper resource cleanup and temporary file management

## Integration

This script can be easily integrated into:

- **CI/CD pipelines** - Automated data uploads
- **Data workflows** - Part of larger data processing pipelines
- **Batch operations** - Upload multiple projects programmatically
- **Scheduled tasks** - Regular data synchronization

## Troubleshooting

### Common Issues

1. **Import errors**: Ensure all required packages are installed
2. **Authentication failures**: Check environment variables and tokens
3. **Connection timeouts**: Verify network connectivity and H2O Cloud environment URL
4. **File permission errors**: Ensure read access to local files and write access to temp directory
5. **Empty uploads**: Verify directory structure matches expected format

### Debug Mode

For debugging, you can modify the script to add more verbose logging or run with Python's verbose flag:

```bash
python -v simple_drive_upload.py --project-path "data" --project-name "test"
```

## Related Files

- `Simple_Drive_Upload.ipynb` - Original Jupyter notebook
- `drive_to_t2e_integration.py` - Integration script for Text2Everything
- `requirements_drive_integration.txt` - Required dependencies
